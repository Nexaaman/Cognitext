{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aman/Desktop/Cognitext/research'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    save_dir: Path\n",
    "    batch_size: 4\n",
    "    max_length: int\n",
    "    stride: int \n",
    "    shuffle: True \n",
    "    drop_last: True \n",
    "    num_workers: int\n",
    "    vocab_size: int       # Vocabulary size (e.g., for GPT-2)\n",
    "    emb_dim: int            # Embedding dimension (reduce this if necessary)\n",
    "    context_length: int    # Max sequence length (reduced from 1024 to 512 to fit in memory)\n",
    "    n_heads: int             # Number of attention heads\n",
    "    n_layers: int            # Reduced number of transformer blocks (reduce to fit in 15GB)\n",
    "    drop_rate: int       # Dropout rate\n",
    "    ff_dim: int           # Feedforward dimension\n",
    "    qkv_bias: bool         # Bias in query/key/value layers\n",
    "    learning_rate: float\n",
    "    tokenizer: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cognitext.utils.common import read_yaml, create_directories\n",
    "from Cognitext.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config = CONFIG_FILE_PATH,  params = PARAMS_FILE_PATH):\n",
    "        self.params = read_yaml(params)\n",
    "        self.config = read_yaml(config)\n",
    "    \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_training\n",
    "        params = self.params.DataLoaderParams\n",
    "\n",
    "       \n",
    "\n",
    "        get_training_config =  ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path= config.data_path,\n",
    "            save_dir= config.save_dir,\n",
    "            batch_size = params.batch_size,\n",
    "            max_length= params.max_length,\n",
    "            stride= params.stride, \n",
    "            shuffle= params.shuffle, \n",
    "            drop_last= params.drop_last, \n",
    "            num_workers= params.num_workers,\n",
    "            vocab_size= params.vocab_size,      \n",
    "            emb_dim= params.emb_dim,            \n",
    "            context_length= params.context_length,    \n",
    "            n_heads= params.n_heads,            \n",
    "            n_layers= params.n_layers,           \n",
    "            drop_rate= params.drop_rate,       \n",
    "            ff_dim= params.ff_dim,      \n",
    "            qkv_bias= params.qkv_bias,        \n",
    "            learning_rate= params.learning_rate,\n",
    "            tokenizer= config.tokenizer\n",
    "        )\n",
    "        return get_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "from torch.amp import GradScaler\n",
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromJSON(Dataset):\n",
    "    def __init__(self,config = ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.tokenizer = self.config.tokenizer\n",
    "        self.json_path = self.config.data_path\n",
    "\n",
    "        with open(self.json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.input_ids = [torch.tensor(item[\"input_ids\"]) for item in self.data]\n",
    "        self.target_ids = [torch.tensor(item[\"target_ids\"]) for item in self.data]\n",
    "\n",
    "        self.tokenizer = self.config.tokenizer\n",
    "        self.max_length = self.config.max_length\n",
    "        self.stride = self.config.stride\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "    def get_train_val(self , dataset):\n",
    "        train_loader = DataLoader(dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(dataset, batch_size=self.config.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import save_file, load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config=ModelTrainerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        create_directories([self.config.root_dir])\n",
    "\n",
    "        self.tok_emb = nn.Embedding(self.config.vocab_size , self.config.emb_dim)\n",
    "        self.pos_emb = nn.Embedding(self.config.max_length , self.config.emb_dim)\n",
    "        self.drop_emb = nn.Dropout(self.config.drop_rate)\n",
    "\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[self.TransformerBlock(self.config) for _ in range(self.config.n_layers)]\n",
    "        )\n",
    "\n",
    "        self.final_norm = nn.LayerNorm(self.config.emb_dim)\n",
    "\n",
    "        self.out_head = nn.Linear(self.config.emb_dim ,self.config.vocab_size, bias=False)\n",
    "\n",
    "        self.tokenizer = self.config.tokenizer\n",
    "\n",
    "    \n",
    "    class TransformerBlock(nn.Module):\n",
    "\n",
    "        def __init__(self, config=ModelTrainerConfig):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "\n",
    "            self.att = nn.MultiheadAttention(self.config.emb_dim, self.config.n_heads, dropout=self.config.drop_rate)\n",
    "            self.ff = Model.FeedForward(self.config)\n",
    "\n",
    "            self.norm1 = nn.LayerNorm(self.config.emb_dim)\n",
    "            self.norm2 = nn.LayerNorm(self.config.emb_dim)\n",
    "            self.drop = nn.Dropout(self.config.drop_rate)\n",
    "\n",
    "        def forward(self, x):\n",
    "            shortcut = x\n",
    "            x = self.norm1(x)\n",
    "            x, _ = self.att(x,x,x)\n",
    "            x = self.drop(x)\n",
    "            x = x + shortcut\n",
    "\n",
    "            shortcut = x\n",
    "            x = self.norm2(x)\n",
    "            x = self.ff(x)\n",
    "            self.norm2(x)\n",
    "            x = x+ shortcut\n",
    "\n",
    "            return x\n",
    "        \n",
    "    class FeedForward(nn.Module):\n",
    "\n",
    "        def __init__(self, config=ModelTrainerConfig):\n",
    "            super().__init__()\n",
    "\n",
    "            self.config = config\n",
    "\n",
    "            self.ff = nn.Sequential(\n",
    "                nn.Linear(self.config.emb_dim, self.config.ff_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(self.config.ff_dim, self.config.emb_dim),\n",
    "                nn.Dropout(self.config.drop_rate)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.ff(x)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "\n",
    "            batch_size, seq_len = in_idx.shape\n",
    "            tok_embeds = self.tok_emb(in_idx)\n",
    "            pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "            \n",
    "            x = tok_embeds + pos_embeds\n",
    "            x = self.drop_emb(x)\n",
    "            \n",
    "            x = self.trf_blocks(x)\n",
    "           \n",
    "            x = self.final_norm(x)\n",
    "            logits = self.out_head(x)\n",
    "            return logits\n",
    "        \n",
    "    def calc_loss_batch(self, input_batch, target_batch, device):\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "           \n",
    "            logits = self(input_batch)\n",
    "\n",
    "            loss = F.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "            return loss\n",
    "        \n",
    "    def calc_loss_loader(self, data_loader, device, num_batches=None):\n",
    "            total_loss = 0.\n",
    "            if len(data_loader) == 0:\n",
    "                return float(\"nan\")\n",
    "            elif num_batches is None:\n",
    "                num_batches = len(data_loader)\n",
    "            else:\n",
    "                num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "            \n",
    "            for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "                if i < num_batches:\n",
    "                   \n",
    "                    loss = self.calc_loss_batch(input_batch, target_batch, device)\n",
    "                    total_loss += loss.item()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "           \n",
    "            return total_loss / num_batches\n",
    "    \n",
    "    def evaluate_model(self, train_loader, val_loader, device, eval_iter):\n",
    "        self.eval()  \n",
    "        with torch.no_grad():\n",
    "            train_loss = self.calc_loss_loader(train_loader, device, eval_iter)\n",
    "            val_loss = self.calc_loss_loader(val_loader, device, eval_iter)\n",
    "        self.train()  \n",
    "        return train_loss, val_loss\n",
    "\n",
    "    def text_to_token_ids(self, text):\n",
    "        \n",
    "        encoded = self.tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "        encoded_tensor = torch.tensor(encoded).unsqueeze(0)  \n",
    "        return encoded_tensor\n",
    "\n",
    "    def token_ids_to_text(self, token_ids):\n",
    "        \n",
    "        flat = token_ids.squeeze(0)  \n",
    "        return self.tokenizer.decode(flat.tolist())\n",
    "\n",
    "    def generate_and_print_sample(self, start_context, device):\n",
    "        self.eval() \n",
    "        context_size = self.pos_emb.weight.shape[0]\n",
    "        encoded = self.text_to_token_ids(start_context).to(device)\n",
    "        with torch.no_grad():\n",
    "            token_ids = self.generate_text_simple(encoded, 50, context_size)\n",
    "            decoded_text = self.token_ids_to_text(token_ids)\n",
    "            print(decoded_text.replace(\"\\n\", \" \")) \n",
    "        self.train()  \n",
    "\n",
    "    def generate_text_simple(self, idx, max_new_tokens, context_size):\n",
    "       \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -context_size:]  \n",
    "            with torch.no_grad():\n",
    "                logits = self(idx_cond)  \n",
    "            logits = logits[:, -1, :] \n",
    "            probas = torch.softmax(logits, dim=-1)  \n",
    "            idx_next = torch.argmax(probas, dim=-1, keepdim=True)  \n",
    "            idx = torch.cat((idx, idx_next), dim=1)  \n",
    "        return idx\n",
    "    \n",
    "    def train_model(self,model, train_loader, val_loader, device , epochs=5, eval_interval=100):\n",
    "    \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.config.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.95)\n",
    "        model = model.to(device)\n",
    "\n",
    "        scaler = GradScaler()\n",
    "        train_losses, val_losses = [], []\n",
    "        tokens_seen = []\n",
    "\n",
    "        accumulation_steps = 4 \n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "\n",
    "            epoch_loss = 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for i, (input_batch, target_batch) in enumerate(train_loader):\n",
    "                input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            \n",
    "                with autocast(device_type='cuda' if device == torch.device('cuda') else 'cpu'):\n",
    "                    logits = model(input_batch)\n",
    "                    loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), target_batch.view(-1))\n",
    "\n",
    "        \n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "            \n",
    "                if (i + 1) % accumulation_steps == 0:\n",
    "            \n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                    global_step += 1\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                \n",
    "                    scheduler.step()\n",
    "\n",
    "            \n",
    "                if global_step % eval_interval == 0:\n",
    "                    val_loss = model.evaluate_model(train_loader, val_loader, device, eval_iter=10)\n",
    "                    print(f'Epoch {epoch+1}, Step {global_step}, Train Loss: {epoch_loss / (i+1)}, Val Loss: {val_loss}')\n",
    "                    train_losses.append(epoch_loss / (i + 1))\n",
    "                    val_losses.append(val_loss)\n",
    "                    tokens_seen.append(global_step * self.config.batch_size)\n",
    "\n",
    "            print(f\"End of Epoch {epoch+1}: Average Training Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "        model.plot_losses(list(range(epochs)), tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, config = ModelTrainerConfig):\n",
    "        config = config\n",
    "        create_directories([config.save_dir])\n",
    "        \n",
    "        model_state_dict = model.state_dict()\n",
    "        save_file(model_state_dict, os.path.join(config.save_dir, \"model.safetensors\"))\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        optimizer_state_dict = optimizer.state_dict()\n",
    "        save_file(optimizer_state_dict, os.path.join(config.save_dir, \"optimizer_state.safetensors\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-21 13:35:41,903: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-21 13:35:42,062: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-21 13:35:42,069: INFO: common: created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "get_training_config = config.get_trainer_config()\n",
    "dataset = DatasetFromJSON(config=get_training_config)\n",
    "train_loader, val_loader = dataset.get_train_val(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-21 13:46:58,675: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-21 13:46:58,683: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-21 13:46:58,689: INFO: common: created directory at: artifacts]\n",
      "[2024-09-21 13:46:58,694: INFO: common: created directory at: artifacts/model_trained]\n",
      "Model already present at =>  artifacts/model_trained/model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    get_training_config = config.get_trainer_config()\n",
    "    model = Model(config=get_training_config)\n",
    "\n",
    "    if os.path.exists(os.path.join(get_training_config.save_dir , \"model.safetensors\")):\n",
    "        print(f\"Model already present at =>  {get_training_config.save_dir}\")\n",
    "\n",
    "    else:\n",
    "        model = (model.train_model(model,train_loader,val_loader, device))\n",
    "        save(model, get_training_config)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
